{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Creditcard_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Class'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_random_sampling(X, y, size=0.2):\n",
    "    while True:\n",
    "        X_sample, _, y_sample, _ = train_test_split(X, y, train_size=size, random_state=42)\n",
    "        if len(np.unique(y_sample)) > 1:\n",
    "            return X_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def systematic_sampling(X, y, size=0.2):\n",
    "    n = len(X)\n",
    "    step = max(1, int(1 / size)) \n",
    "    indices = np.arange(0, n, step)[:int(size * n)]\n",
    "    X_sample = X.iloc[indices]\n",
    "    y_sample = y.iloc[indices]\n",
    "    if len(np.unique(y_sample)) > 1:\n",
    "        return X_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sampling(X, y, size=0.2):\n",
    "    X_sample, _, y_sample, _ = train_test_split(X, y, train_size=size, stratify=y, random_state=42)\n",
    "    return X_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sampling(X, y, n_clusters=5):\n",
    "    while True:\n",
    "        clusters = pd.qcut(X.index, n_clusters, labels=False)  \n",
    "        chosen_cluster = np.random.choice(range(n_clusters))\n",
    "        indices = X.index[clusters == chosen_cluster]\n",
    "        X_sample = X.loc[indices]\n",
    "        y_sample = y.loc[indices]\n",
    "        if len(np.unique(y_sample)) > 1:\n",
    "            return X_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_sampling(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    return skf.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_methods = {\n",
    "    \"Simple Random\": simple_random_sampling,\n",
    "    \"Systematic\": systematic_sampling,\n",
    "    \"Stratified\": stratified_sampling,\n",
    "    \"Cluster\": cluster_sampling,\n",
    "    \"Cross-Validation\": cross_validation_sampling,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"XGB\": XGBClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_with_sampling(X, y, sampling_methods, models):\n",
    "    results = {}\n",
    "\n",
    "    for method_name, sampler in sampling_methods.items():\n",
    "        results[method_name] = {}\n",
    "\n",
    "        if method_name == \"Cross-Validation\":\n",
    "            # Handle cross-validation separately\n",
    "            for model_name, model in models.items():\n",
    "                accuracies = []\n",
    "                skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "                for train_idx, test_idx in skf.split(X, y):\n",
    "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "                    \n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "                \n",
    "                results[method_name][model_name] = np.mean(accuracies)\n",
    "        else:\n",
    "            # Handle other sampling methods\n",
    "            X_sample, y_sample = sampler(X, y)\n",
    "            for model_name, model in models.items():\n",
    "                # Split sampled data into train-test sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, random_state=42)\n",
    "                \n",
    "                # Train and evaluate model\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                results[method_name][model_name] = accuracy\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SMOTE(Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_models_with_sampling(X_balanced, y_balanced, sampling_methods, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Sampling Method for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}\n",
    "for method, method_results in results.items():\n",
    "    for model, accuracy in method_results.items():\n",
    "        if model not in final_results or final_results[model]['accuracy'] < accuracy:\n",
    "            final_results[model] = {'sampling_method': method, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Sampling Technique for Each Model:\n",
      "Logistic Regression: Cluster with Accuracy = 0.96\n",
      "XGB: Cross-Validation with Accuracy = 0.99\n",
      "Random Forest: Cross-Validation with Accuracy = 1.00\n",
      "SVM: Cluster with Accuracy = 0.83\n",
      "KNN: Cluster with Accuracy = 0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Sampling Technique for Each Model:\")\n",
    "for model, result in final_results.items():\n",
    "    print(f\"{model}: {result['sampling_method']} with Accuracy = {result['accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"sampling_results.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
